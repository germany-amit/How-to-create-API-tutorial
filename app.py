"""
Agentic AI API Engineer — Streamlit MVP (Free/Open-Source)
Cradle-to-cradle: requirement → spec → backend → live API → client demo → interactive tryout.
Uses local open-source LLM to generate API from natural language.
"""

import streamlit as st
import yaml
import io
import zipfile
import json
from datetime import datetime
from jinja2 import Template
import re

# --- Optional: transformers for free LLM -----------------------------------
from transformers import pipeline

st.set_page_config(page_title="Agentic AI API Engineer", layout="wide")

# Load a small open-source instruction-tuned model
@st.cache_resource(show_spinner=True)
def load_llm():
    generator = pipeline("text-generation", model="declare-lab/flan-alpaca-small", device=-1)
    return generator

generator = load_llm()

# --- Core Generators -------------------------------------------------------

def generate_openapi(api_name, version, desc, endpoints):
    spec = {
        'openapi': '3.0.3',
        'info': {'title': api_name, 'version': version, 'description': desc},
        'servers': [{'url': '{{baseUrl}}'}],
        'paths': {}
    }
    for ep in endpoints:
        path = ep['path']
        method = ep['method'].lower()
        spec['paths'].setdefault(path, {})[method] = {
            'summary': ep.get('summary', ''),
            'responses': {'200': {'description': 'Success'}}
        }
    return yaml.safe_dump(spec, sort_keys=False)

def scaffold_fastapi_app(api_name, version, endpoints):
    template = Template("""
from fastapi import FastAPI

app = FastAPI(title="{{title}}", version="{{version}}")

@app.get("/health")
async def health():
    return {"status": "ok", "timestamp": "{{timestamp}}"}

{% for ep in endpoints %}
@app.{{ep.method.lower()}}("{{ep.path}}")
async def {{ep.func_name}}():
    return {"demo": "{{ep.summary}}"}
{% endfor %}
""")
    return template.render(title=api_name, version=version, endpoints=endpoints, timestamp=datetime.utcnow().isoformat())

def scaffold_client_demo(endpoints):
    code = ["""import requests
BASE_URL = "http://localhost:8000"
"""]
    for ep in endpoints:
        code.append(f"resp = requests.{ep['method'].lower()}(f'{{BASE_URL}}{ep['path']}')")
        code.append("print(resp.status_code, resp.text)")
    return "\n".join(code)

def make_zip(files: dict):
    buf = io.BytesIO()
    with zipfile.ZipFile(buf, "w", zipfile.ZIP_DEFLATED) as z:
        for fname, content in files.items():
            z.writestr(fname, content)
    buf.seek(0)
    return buf

# --- AI-Powered API Generation --------------------------------------------

def generate_api_details_from_prompt(user_prompt):
    """
    Generate API details using small open-source LLM (no API key needed)
    """
    prompt = f"""
    You are an API designer. Convert this user request into a JSON object with
    'name', 'version', 'description', and 'endpoints' (each endpoint has 'path', 'method', 'summary', 'func_name').
    User request: {user_prompt}
    """
    try:
        result = generator(prompt, max_length=512, do_sample=True)[0]['generated_text']
        match = re.search(r'({.*})', result, re.DOTALL)
        if match:
            return json.loads(match.group(1))
    except Exception:
        pass

    # fallback default if parsing fails
    return {
        "name": "CustomAPI",
        "version": "0.1.0",
        "description": "Generated by local LLM",
        "endpoints": [
            {"path": "/items", "method": "GET", "summary": "List items", "func_name": "list_items"},
            {"path": "/items", "method": "POST", "summary": "Create item", "func_name": "create_item"},
        ]
    }

# --- Prebuilt Demos --------------------------------------------------------

demo_apis = {
    "Todo API": [
        {"path": "/todos", "method": "GET", "summary": "List todos", "func_name": "list_todos"},
        {"path": "/todos", "method": "POST", "summary": "Create todo", "func_name": "create_todo"},
    ],
    "Notes API": [
        {"path": "/notes", "method": "GET", "summary": "List notes", "func_name": "list_notes"},
        {"path": "/notes", "method": "POST", "summary": "Create note", "func_name": "create_note"},
    ],
    "Calculator API": [
        {"path": "/add", "method": "GET", "summary": "Add two numbers", "func_name": "add"},
        {"path": "/multiply", "method": "GET", "summary": "Multiply two numbers", "func_name": "multiply"},
    ]
}

# --- UI --------------------------------------------------------------------

st.title("Agentic AI API Engineer — Free Open-Source Cradle-to-Cradle")
st.caption("Generate simple APIs live from natural language requirements using free LLM.")

# Session state for custom requirement
if 'custom_req' not in st.session_state:
    st.session_state.custom_req = "I want a simple API that manages tasks."

choice = st.selectbox("Choose Demo API", list(demo_apis.keys()) + ["Custom requirement"])

if choice != "Custom requirement":
    endpoints = demo_apis[choice]
    api_name = choice
    version = "0.1.0"
    desc = f"Auto-generated {choice} using free Agentic AI API Engineer."
    st.session_state.custom_req = "I want a simple API that manages tasks."
else:
    api_name = st.text_input("API Name", value="Custom API", disabled=True)
    version = st.text_input("Version", value="0.1.0", disabled=True)
    desc = st.text_area("Description", value="Generated from natural language requirement.", disabled=True)
    st.session_state.custom_req = st.text_area("Enter requirement", value=st.session_state.custom_req, height=150)
    endpoints = []

if st.button("Generate API from scratch"):
    if choice == "Custom requirement":
        if not st.session_state.custom_req:
            st.error("Please enter a requirement to generate a custom API.")
            st.stop()

        with st.spinner("Generating API details with local LLM..."):
            api_details = generate_api_details_from_prompt(st.session_state.custom_req)
            api_name = api_details.get("name", "CustomAPI")
            version = api_details.get("version", "0.1.0")
            desc = api_details.get("description", "Generated by local LLM.")
            endpoints = api_details.get("endpoints", [])

            if not endpoints:
                st.warning("No endpoints generated. Using fallback.")
                endpoints = [
                    {"path": "/items", "method": "GET", "summary": "List items", "func_name": "list_items"},
                    {"path": "/items", "method": "POST", "summary": "Create item", "func_name": "create_item"},
                ]

    # Generate outputs
    openapi_yaml = generate_openapi(api_name, version, desc, endpoints)
    fastapi_code = scaffold_fastapi_app(api_name, version, endpoints)
    client_code = scaffold_client_demo(endpoints)

    st.subheader("OpenAPI Spec")
    st.code(openapi_yaml, language='yaml')

    st.subheader("FastAPI Code")
    st.code(fastapi_code, language='python')

    st.subheader("Client Demo (how to use the API)")
    st.code(client_code, language='python')

    st.subheader("Try API Now (simulated)")
    for ep in endpoints:
        st.button(f"Call {ep['method']} {ep['path']}")
        st.json({"message": f"Called {ep['method']} {ep['path']}", "summary": ep['summary'], "status": "ok"})

    files = {
        'openapi.yaml': openapi_yaml,
        'backend/main.py': fastapi_code,
        'client_demo.py': client_code,
        'README.md': f"# {api_name}\n\n{desc}\n"
    }
    zipbuf = make_zip(files)
    st.download_button("Download API Project ZIP", zipbuf, file_name=f"{api_name.replace(' ','_')}_cradle.zip")

st.info("Cradle-to-cradle API engineering: requirement → spec → backend → client demo → simulated try.")
